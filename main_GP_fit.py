###########################################
'''
All tests go here.
Plots, functions, tf fns, imported.
'''
###########################################
import tensorflow as tf
if tf.__version__[0] == '2':
    import tensorflow.compat.v1 as tf
    tf.disable_v2_behavior()

import tensorflow_probability as tfp
tfk = tf.keras
tfkl = tf.keras.layers
tfb = tfp.bijectors
tfd = tfp.distributions
tfpl = tfp.layers

import imports as im
import numpy as np
import pandas as pd

import gp_functions as gpf
import plots as plts




def load_csv(filename):
    # e = pd.read_csv(filename)
    e = pd.read_csv(open(filename, 'rU'), encoding='utf-8', engine='c')
    return e


#################################################################
def TEST_tracer_data_GP_():

    '''
    ----------------------------------------------------
    ## cvs pandas dataframe import ##
    ----------------------------------------------------
    ## 3D input GP fitting problem. ## (sinusoid is 3D)
    1. COORDINATES : project Z coord to XY plane 3D -> 2D
    2. TRACER : 1D
    3. obs : combined 1. & 2. -> 3D
    Coordinates and corresponding tracer value for 1 time step.
    4.1 scale - take average tracer over timesteps, remains 3D
    ----------------------------------------------------
    ## 6D input GP fitting problem ##
    4.2 scale - then scale GP dimensions to get
            Z coordinate,
            T time,
            P pressure ...
    ----------------------------------------------------
    ## Bijectors in tf ##
    transforming rand variables, between input and output rv.s
    unless data is generated by gaussian - assumption - can combine distributions
    forward - compute samples
    inverse - compute probabilities
    ----------------------------------------------------
    Challenges:
    - sampling with MCMC
    - switch to tf2.0
    - plot kernel and find better kernel from data
    ----------------------------------------------------
    ## VAE - variational autoencoders - parameterize probabilistic graphical model with NN ##
    take different distributions, fit it with Monte Carlo Variational Inference
    (tf automatic differentiation)
    - data is embedded into lower dimensional space
    ----------------------------------------------------
    '''
    ## Dimensions and replacements ##
    '''
    - t_idx : 1 D tracer
    - t_sel_idx : selection of close to section tracer training points
    - idx : training input
    - obs : output!
    - linsp : linspace
    - w : distance from BEGIN along section line
    - w_proj : altered xy to w when taking section cut
    - pred_idx : prediction input
    - pred_obs : prediction output
    - o : filler column full of 0s 

    > FROM DATASET : 
    obs_idx_pts (60, 2) : xy_idx
    obs (60, 1) : t_idx
    obs_rowvec  (60,) : t_idx.T
    pts (60, 3) : xyt_idx

    > CALCULATION :
    obs_proj_idx_pts (200, 1) : w_linsp
    sel_pts (7, 3) : xyt_sel_idx
    sel_obs (7,) : t_sel_idx
    ext_sel_pts (7, 4) : xytw_sel_idx
    train_idx_pts_along_section_line (7, 1) : w_sel_idx    
    line_idx (200, 1) : w_pred_idx_linsp
    line_XY (200, 3) : xyo_pred_idx_linsp
    line_obs (200,) : t_pred_obs_line_linsp
    pred_idx_pts (2500, 2) xy_pred_pts
    pred_sel_idx_pts (7, 1) t_pred_pts
    '''
#################################################################
    PLOTS = True
    TRACER_ONLY = False
    PRESSURE_ONLY = False
    ALL = False
    LOAD_TO_CSV = False
    FILENAME = "all_data_520_720.csv"
    TIMERANGE = [220,221]

    NUM_PTS_GEN = 1000  # 1000
    RANGE_PTS = [-2, 2]
    COORDINATE_RANGE = np.array([[-2., 2.], [-2., 2.]])  # xrange, yrange
    NUM_TRAINING_POINTS = 60

    AMPLITUDE_INIT = np.array([.1, .1]) # [0.1, 0.1]
    LENGTHSCALE_INIT = np.array([.1, .1]) # [0.1, 0.1]
    LEARNING_RATE = .1 #.01
    INIT_OBSNOISEVAR = 1e-6
    INIT_OBSNOISEVAR_ = 0.001 # 0.001
    XEDGES = 60
    YEDGES = 60 #60
    LOGDIR = "./log_dir_gp/gp_plot/"
    NUM_ITERS = 1000  # 1000
    PRED_FRACTION = 50  # 50
    LOGCHECKPT = "model.ckpt"
    NUM_SAMPLES = 20  # 50
    PLOTRASTERPOINTS = 20 # 60 this is SQUARED to to get smooth samples.
    LINSPACE_LINE = 400 # 200
    SIZEOFDATASET = 200

    # indoor = drs.load_csv('/Ubuntu_18/data_room/data_selections_csv/indoor_003.csv')
    # ds = drs.load_csv('roomselection_0001.600.csv')



    # def import_to_GP_fit(CSV):
    ds = load_csv('roomselection_1800.csv')
    # randomize index set.
    ds_idx_length = ds.shape[0]
    ds_idx_arr = np.linspace(0, ds_idx_length -1, ds_idx_length ).T
    np.random.shuffle(ds_idx_arr)
    ds_r = np.array(ds_idx_arr[:SIZEOFDATASET])

    ds = ds.iloc[ds_r, :]

    xyzt_idx = ds[['Points:0', 'Points:1', 'Points:2', 'Temperature']]
    xyz_idx = ds[['Points:0', 'Points:1', 'Points:2']]
    xy_idx = ds[['Points:0', 'Points:1']]
    xyt_idx = ds[['Points:0', 'Points:1', 'Temperature']]
    x_idx = ds[['Points:0']]
    y_idx = ds[['Points:1']]
    t_idx = ds[['Temperature']]

    ###############################
    # xyzt_idx = np.array(xyzt_idx[:1000,:])
    # xyz_idx = np.array(xyz_idx[:1000,:])
    # xy_idx = np.array(xy_idx[:1000,:])
    # xyt_idx = np.array(xyt_idx[:1000,:])
    # x_idx = np.array(x_idx[:1000,:])
    # y_idx = np.array(y_idx[:1000,:])
    # t_idx = np.array(t_idx[:1000,:])
    # ##############################
    x_min = np.min(x_idx)
    x_max = np.max(x_idx)
    y_min = np.min(y_idx)
    y_max = np.max(y_idx)

    y_max = 68.
    BEGIN = [x_min, y_min]
    END = [x_max, y_max]

    BEGIN = np.array(BEGIN).astype(dtype=np.float64).flatten()
    END = np.array(END).astype(dtype=np.float64).flatten()


    EPSILON = 0.2

    xyt_sel_idx = gpf.capture_close_3d_pts_with_2d_distance(xyt_idx, BEGIN, END, EPSILON)  # 2D distance, 3D pts

    if PLOTS:
        plts.plot_range_of_values_and_sel(12,4, xyt_idx, xyt_sel_idx)
        plts.plot_2d_observations(12, 12, xyt_idx, xyt_sel_idx, BEGIN, END)
        plts.plot_capture_line(12, 12, xyt_sel_idx, BEGIN, END)
        plts.plot_val_histogram(10, 4, np.array(t_idx).T.flatten())

    ##############

    ##############
    sess = gpf.reset_session()

    amp, amp_assign, amp_p, lensc, lensc_assign, lensc_p, emb, emb_assign, emb_p, obs_noise_var \
        = gpf.tf_Placeholder_assign_test(AMPLITUDE_INIT, LENGTHSCALE_INIT, INIT_OBSNOISEVAR)

    # xy_idx, t_idx = dg.generate_noisy_2Dsin_data(NUM_TRAINING_POINTS, 0.001, COORDINATE_RANGE)
    print("--------------")
    w_linsp = np.linspace(BEGIN, END, LINSPACE_LINE)
    w_linsp = gpf.project_2d_to_line_coordinates(w_linsp, BEGIN, END) #2D coord linspace between BEGIN and END
    w_linsp = gpf.create_1d_w_line_coords(w_linsp, BEGIN, END)  # 2D to 1D
    print(w_linsp.shape) # is it really going through w?

    t_idx = np.array(t_idx).reshape(-1, 1)  # to column vector
    # xyt_idx = gpf.add_dimension(xy_idx, t_idx) # TODO use: append
    xyt_sel_idx = gpf.capture_close_3d_pts_with_2d_distance(xyt_idx, BEGIN, END, EPSILON)  # 3D # TODO use: capture_close_3d_pts_with_2d_distance

    t_sel_idx = np.zeros((0, 1))
    for i in xyt_sel_idx[:, 2]: # 3rd D TODO replace with shape ...
        t_sel_idx = np.concatenate((t_sel_idx, i), axis=None)

    #TODO fix: d = np.dot((v - u), (x - u)) / np.linalg.norm(v - u)

    xytw_sel_idx = gpf.extend_pts_with_line_coord(xyt_sel_idx, BEGIN, END)  # 4D

    w_sel_idx = gpf.project_2d_to_line_coordinates(xyt_sel_idx, BEGIN, END)
    w_sel_idx = gpf.create_1d_w_line_coords(w_sel_idx, BEGIN, END)  # 1D

    w_pred_idx_linsp = gpf.create_line_coord_linspace(BEGIN, END, LINSPACE_LINE)  # 1D
    xyo_pred_idx_linsp = gpf.create_line_linspace(BEGIN, END, LINSPACE_LINE)  # 2D
    t_pred_obs_line_linsp = gpf.create_Z_sin_along_line_linspace(xyo_pred_idx_linsp)  # 1D

    kernel, log_likelihood, lls, saver, amp, lensc,obs_noise_var = \
        gpf.gp_train_and_hyperparameter_optimize(
            amp, # (2,)
            amp_assign, # tensor (2,)
            amp_p, # placeholder (2,)
            lensc, lensc_assign, lensc_p, emb,
            xy_idx, # df (200,2)
            t_idx, # ndarray (200,1)
            obs_noise_var, # tensor ()
            LEARNING_RATE, NUM_ITERS, LOGDIR, LOGCHECKPT, sess)

    print("lensc",lensc)
    print("amp",amp)

    pred_x = np.linspace(-2, 2, PRED_FRACTION, dtype=np.float64)
    pred_y = np.linspace(-2, 2, PRED_FRACTION, dtype=np.float64)
    xy_pred_pts = gpf.create_meshgrid(pred_x,pred_y,PRED_FRACTION)  # posterior = predictions
    t_pred_pts = gpf.project_2d_to_line_coordinates(xyt_sel_idx, BEGIN, END)  # 1D observations along x.
    # print("w_pred_idx_linsp.shape : ", w_pred_idx_linsp.shape) #(200, 1)
    # print("obs_idx_pts_along_section_line.shape : ", w_sel_idx.shape) #(100, 1)
    # print("t_sel_idx.shape : ", t_sel_idx.shape) #(100, )
    # print(repr(w_sel_idx))
    # print(repr(t_sel_idx))

    # Gaussian process regression model
    # gprm = gpf.tf_gp_regression_model(kernel, xy_pred_pts, xy_idx, t_idx.T, obs_noise_var, 0.)
    gprm_section = gpf.tf_gp_regression_model(kernel, w_pred_idx_linsp, w_sel_idx, t_sel_idx, obs_noise_var, 0.)

    # posterior_mean_predict = im.tfd.gp_posterior_predict.mean()
    # posterior_std_predict = im.tfd.gp_posterior_predict.stddev()

    # samples
    # samples = gprm.sample(NUM_SAMPLES)
    # samples_ = sess.run(samples)

    samples_section = gprm_section.sample(NUM_SAMPLES)
    samples_section_ = sess.run(samples_section)

    H = gpf.calc_H(XEDGES, YEDGES, lensc, lensc_assign, lensc_p, amp, amp_assign, amp_p, log_likelihood, sess)
    # 5th dimension = log-likelihood at points xyzw
    # emb_p = im.tf.placeholder(shape=[XEDGES, YEDGES], dtype=np.float32, name='emb_p')
    # emb = im.tf.Variable(im.tf.zeros([XEDGES, YEDGES]), name="log_probability_embedding")
    # emb_as_op = emb.assign(emb_p, name='emb_as_op')

    # [_] = sess.run([emb_as_op], feed_dict={emb_p: H})
    saver.save(sess, im.os.path.join(LOGDIR, LOGCHECKPT), NUM_ITERS + 1)

    # plts.plot_kernel(12,4, kernel,BEGIN, END)

    print("obs_idx_pts = xy_idx",xy_idx.shape)
    print("obs = t_idx",t_idx.shape)
    print("obs_rowvec ",t_idx.T.shape)
    print("obs_proj_idx_pts = w_linsp",w_linsp.shape)
    print("pts = xyt_idx",xyt_idx.shape)
    print("sel_pts = xyt_sel_idx",xyt_sel_idx.shape)
    print("sel_obs = t_sel_idx",t_sel_idx.shape)
    # print("ext_sel_pts",ext_sel_pts.shape)
    print("train_idx_pts_along_section_line = w_sel_idx",w_sel_idx.shape)
    print("line_idx = w_pred_idx_linsp",w_pred_idx_linsp.shape)
    print("line_XY = xyo_pred_idx_linsp",xyo_pred_idx_linsp.shape)
    print("line_obs = t_pred_obs_line_linsp",t_pred_obs_line_linsp.shape)
    print("pred_idx_pts = xy_pred_pts",xy_pred_pts.shape)
    print("pred_sel_idx_pts = t_pred_pts",t_pred_pts.shape)
    print("----------------------")


    # PLOTS
    if PLOTS:
        pass


        # plts.plot_sin3D_rand_points(12, 12, COORDINATE_RANGE, obs_idx_pts, obs, PLOTRASTERPOINTS)
        #
        # # plts.plot_section_observations(12, 7, ext_sel_pts, BEGIN, END)
        # # GP
        plts.plot_loss_evolution(12, 4, lls)
        plts.plot_marginal_likelihood3D(XEDGES, H)
        # # plts.plot_samples2D(12,5,1, pred_idx_pts, obs_idx_pts, obs, samples_, NUM_SAMPLES)
        plts.plot2d_samples_section(12, 4, xytw_sel_idx, w_pred_idx_linsp, w_linsp, t_pred_obs_line_linsp, samples_section_,
                                             NUM_SAMPLES, BEGIN, END)

        # plts.plot_samples3D(12, 12, 0, xy_pred_pts, samples_section_, xy_idx, t_idx, PRED_FRACTION, BEGIN, END)

        # # plts.plot_gp_2D_samples(12,7, pred_sel_idx_pts, sel_obs, line_idx, line_obs, NUM_SAMPLES, samples_l[:,0:2], samples_coord_along_line, samples_z)

    PLOTS = False



if __name__ == '__main__':
    TEST_tracer_data_GP_()


